# Globally and Locally Consistent Image Completion

[論文PDF](http://iizuka.cs.tsukuba.ac.jp/projects/completion/data/completion_sig2017.pdf)

## 著者
- SATOSHI IIZUKA
- EDGAR SIMO-SERRA
- HIROSHI ISHIKAWA

## 何のための研究？
欠損領域の補間（インペインディング)


## 従来のアプローチとその問題点は？
### 1.パッチベースのアプローチ
#### アプローチ
元の画像からサンプルしたパッチ（局所領域）を（加工して）ターゲット画像にペーストする。サンプルには[PatchMatch](https://gfx.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch.pdf)のようなアルゴリズムを用いることで高速に行うことが可能

#### ○利点
* 画像サイズ、欠損領域が任意のサイズ
* 局所的整合性がある（周りと連続する）

#### ×問題点
* 複雑な構造を復元できない
* 画像にない新しいオブジェクトを生成できない

### 2.context encoder(学習ベース)
#### アプローチ
GANを用いたcontext encoder で　
ピクセルごとの平均二乗誤差とGANの損失関数を組み合わせて学習（ディスクリミネータを用いないで二乗誤差のみで学習すると画像がぼやける）
#### ○利点
* 新しいオブジェクトを生成できる
* 周りとの連続が考慮されていない（結果として連続に見えるが不自然になる）

#### ×問題点
* 画像サイズ、欠損領域が固定
* 処理に時間がかかる


## この論文ではどういうアプローチで問題を解決する？

G×1，D×2の３つのネットワークで構成される．
1. 復元ネットワーク（G）
2. 大域的整合性ネットワーク（D）
3. 局所的整合性ネットワーク（D）
全層が畳み込み層のジェネレータで画像を生成し，画像の大域的な整合性と画像の局所的な整合性をそれぞれのディスクリミネータから得る．
学習はデータセットのランダムな位置に欠損領域を１つ作成して元に戻すよう学習する．

### 1. 復元ネットワーク（ジェネレータ）
入力：画像とマスク（２値）
中間：**dilated conv**（後述）を４つ含む全層畳み込み
出力：復元画像

全層畳み込み層でエンコーダ，デコーダーのモデルを用いて学習する．途中にdilated convを用いることでボケの少ない画像にしている．

#### dilated conv
[元論文](https://arxiv.org/abs/1511.07122)
畳み込みカーネルをより広い範囲にしたもの．
通常のカーネルと同じメモリ，計算量でより広い範囲を"みる"ことができる

従来は生成の過程でダウンサンプルを繰り返し行うことで生成画像がぼやけたものになりがち
dilated convを用いて，通常の畳み込みに比べて少ないダウンサンプリング（２回）で同等の範囲をみることができるためボケの少ない画像が生成できる．

イメージ↓  
![image](https://user-images.githubusercontent.com/60776249/80814319-9ffbe780-8c06-11ea-965a-07dd2a2d77d1.png)
式↓  
![式](https://user-images.githubusercontent.com/60776249/80814624-2c0e0f00-8c07-11ea-96a0-c466119b103e.png)

### 2. 大域的整合性ネットワーク（ディスクリミネータ）
入力：256×256（にリサイズされた生成画像）
中間：畳み込み層（カーネルサイズ:5×5，Stride:2×2）
出力：1024次元ベクトル

256×256にリサイズされた画像から大域的な特徴を学習する．カーネルサイズ5×5でStrideが2×2の畳み込み層で構成され，最後に全結合層を用いて1024次元のベクトルに変換する


### 3. 局所的整合性ネットワーク（ディスクリミネータ）
入力：（欠損領域を中心とした）128×128
中間：畳み込み層（カーネルサイズ:5×5，Stride:2×2）
出力：1024次元ベクトル

欠損領域を中心とした128×128のパッチを切り出して局所的な特徴を学習する．基本的には大域的整合性のネットワークと同じ構成で最終的には1024次元ベクトルになる

### 4.concatenation層
入力：２つのディスクリミネータ(各1024次元)の出力を結合した2048次元ベクトル
出力：sigmoid関数で[0, 1]になった生成画像のReal or Fake の確率

## この論文の主定理，もしくは鍵となる式・図は？（最大2個まで）

![ネットワーク全体像](https://user-images.githubusercontent.com/60776249/80808970-b05a9500-8bfb-11ea-99bd-976dd3fd8e09.png)


## この論文で何が出来るようになった？and/or 何が良くなった？　
* ジェネレーターが畳み込み層であるため任意のサイズの画像，欠損領域を扱える
* 局所的整合性と局所的整合性を両方得ることができる
* （元の画像にない）鼻や目などのオブジェクトを生成できる
これらを同時に達成することがすごい

|                            | パッチベース | context encoder | 提案手法 |
|----------------------------|--------------|-----------------|----------|
| 任意のサイズ               | ○            | ×               | ○        |
| 局所的整合性               | ○            | ×               | ○        |
| 風景の意味（大域的整合性） | ×            | ○               | ○        |
| 新しいオブジェクトの生成   | ×            | ○               | ○        |

## 実験と評価方法
CelebAデータセットを用いて顔の生成タスクを行う．
１０人の被験者がデータセット内のランダムな画像か，復元画像のどちらかを見せられてそれがリアルかフェイクかを判定する．
復元画像がリアルだと判定された率：　77.0%
リアルな画像がリアルだと判定された率： 96.5%  
![UserStudy](https://user-images.githubusercontent.com/60776249/80817859-2c110d80-8c0d-11ea-903d-bb3ad51cfd97.png)

## この論文の問題点や課題は？
失敗するケースがある
* 画像の淵に欠損領域がある場合
* 欠損領域が大きい場合
* 複雑な構造体（人や動物）の一部がマスクされている場合  

![FailCase](https://user-images.githubusercontent.com/60776249/80818660-95455080-8c0e-11ea-8f66-629fef9678e9.png)

![FailCase](https://user-images.githubusercontent.com/60776249/80818793-c6be1c00-8c0e-11ea-920b-b89f813c4b23.png)
